p8105_hw1_yh3554
================

``` r
library(tidyverse)
library(readxl)
```

# Problem 1

Read and clean the data, select the variable we need, and convert entry
variable from character to logical variable.

``` r
p1_df = read_csv(
  "NYC_Transit_Subway_Entrance_And_Exit_Data.csv", 
  col_types = cols(Route8 = "c", Route9 = "c", Route10 = "c", Route11 = "c")) %>%
  janitor::clean_names() %>%
  select(
    line, station_name, station_latitude, station_longitude, 
    starts_with("route"), entry, vending, entrance_type, ada) %>%
  mutate(entry = ifelse(entry == "YES", TRUE, FALSE))
```

#### Description

The data contains 19 variables includes line, station, name, station
latitude, station longitude, 11 routes served, entry, vending, entrance
type, and ADA compliance. The dimension is 19 variables and 1868
observations. First, read the csv file and select the variable we need.
Then change the Route8, Route9, Route10, and Route11 variables to
character variable as same as Route1 to Route7 variables.  
The data is not “tidy” since there are 11 route variables which is not
necessary when we consider which route are selected. It would be easier
if we combine the route variables to a new variable that contains all
the route numbers. However, it would be different if we are focusing on
different aspect such as while we do need to consider the station level
variables.

#### Distinct stations

To find the numbers of distinct stations we need a news dataframe that
has both name and line variables, and use `distinct()` funtion to obtain
all unique combinations. There are 465 distinct stations in this data.

``` r
p1_df %>% 
  select(station_name, line) %>%
  distinct
```

    ## # A tibble: 465 × 2
    ##    station_name             line    
    ##    <chr>                    <chr>   
    ##  1 25th St                  4 Avenue
    ##  2 36th St                  4 Avenue
    ##  3 45th St                  4 Avenue
    ##  4 53rd St                  4 Avenue
    ##  5 59th St                  4 Avenue
    ##  6 77th St                  4 Avenue
    ##  7 86th St                  4 Avenue
    ##  8 95th St                  4 Avenue
    ##  9 9th St                   4 Avenue
    ## 10 Atlantic Av-Barclays Ctr 4 Avenue
    ## # … with 455 more rows

#### ADA Compliant Stations

To find the numbers of ADA compliant stations, we need to use the ada
variable to filter out the station that satisfy the ada compliant. Then
apply `distinct()` function again. There are 84 ADA compliant stations.

``` r
p1_df %>% 
  filter(ada == TRUE) %>%
  select(station_name, line) %>%
  distinct
```

    ## # A tibble: 84 × 2
    ##    station_name                   line           
    ##    <chr>                          <chr>          
    ##  1 Atlantic Av-Barclays Ctr       4 Avenue       
    ##  2 DeKalb Av                      4 Avenue       
    ##  3 Pacific St                     4 Avenue       
    ##  4 Grand Central                  42nd St Shuttle
    ##  5 34th St                        6 Avenue       
    ##  6 47-50th Sts Rockefeller Center 6 Avenue       
    ##  7 Church Av                      6 Avenue       
    ##  8 21st St                        63rd Street    
    ##  9 Lexington Av                   63rd Street    
    ## 10 Roosevelt Island               63rd Street    
    ## # … with 74 more rows

#### Proportion of station entrances/exits without vending allow entrance.

To find the proportion of station entrances/exists without vending allow
entrance, we first want to filter out the entry variable without vending
using `filter()` and `pull()`. After pull out the entry variable it
turns to logical variable. Then we can use `mean()` to compute the
proportion. The proportion is 0.3770.

``` r
p1_df %>%
  filter(vending == "NO") %>%
  pull(entry) %>%
  mean
```

    ## [1] 0.3770492

#### Numbers of dictinct stations serve A

Create two new variables route number and route name using
`pivot_longer()`, then filter out distinct stations that serve A. There
are 60 distinct stations that serve A.

``` r
p1_df %>% pivot_longer(route1:route11,
                       names_to = "station_number",
                       values_to = "route_name") %>%
  filter(route_name == "A") %>%
  select(station_name, line) %>%
  distinct
```

    ## # A tibble: 60 × 2
    ##    station_name                  line           
    ##    <chr>                         <chr>          
    ##  1 Times Square                  42nd St Shuttle
    ##  2 125th St                      8 Avenue       
    ##  3 145th St                      8 Avenue       
    ##  4 14th St                       8 Avenue       
    ##  5 168th St - Washington Heights 8 Avenue       
    ##  6 175th St                      8 Avenue       
    ##  7 181st St                      8 Avenue       
    ##  8 190th St                      8 Avenue       
    ##  9 34th St                       8 Avenue       
    ## 10 42nd St                       8 Avenue       
    ## # … with 50 more rows

#### Numbers of distinct stations are ADA compliant that serve A.

Similar as before, just add ADA compliant to the filter. There are 17
distinct stations are ADA compliant that serve A.

``` r
p1_df %>% pivot_longer(route1:route11,
                       names_to = "station_number",
                       values_to = "route_name") %>%
  filter(route_name == "A", ada == TRUE) %>%
  select(station_name, line) %>%
  distinct
```

    ## # A tibble: 17 × 2
    ##    station_name                  line            
    ##    <chr>                         <chr>           
    ##  1 14th St                       8 Avenue        
    ##  2 168th St - Washington Heights 8 Avenue        
    ##  3 175th St                      8 Avenue        
    ##  4 34th St                       8 Avenue        
    ##  5 42nd St                       8 Avenue        
    ##  6 59th St                       8 Avenue        
    ##  7 Inwood - 207th St             8 Avenue        
    ##  8 West 4th St                   8 Avenue        
    ##  9 World Trade Center            8 Avenue        
    ## 10 Times Square-42nd St          Broadway        
    ## 11 59th St-Columbus Circle       Broadway-7th Ave
    ## 12 Times Square                  Broadway-7th Ave
    ## 13 8th Av                        Canarsie        
    ## 14 Franklin Av                   Franklin        
    ## 15 Euclid Av                     Fulton          
    ## 16 Franklin Av                   Fulton          
    ## 17 Howard Beach                  Rockaway

# Problem 2

Read and clean the data “Mr.Trash Wheel”. Assign appropriate column name
to each variables and exclude rows or columns that containing notes or
non-data entries.

``` r
p2_df1 <- read_excel("Trash Wheel Collection Data.xlsx", sheet = 1) %>%
    janitor::clean_names() %>%
    filter(dumpster != "NA", dumpster != "Grand Total", ) %>%
    select(-c(15, 16)) %>%
    mutate(year = as.integer(year), sports_balls = as.integer(sports_balls))
```

    ## New names:
    ## • `` -> `...15`
    ## • `` -> `...16`

``` r
p2_df2 <- read_excel("Trash Wheel Collection Data.xlsx", sheet = 2) %>%
    janitor::clean_names() %>%
    filter(dumpster != "NA", dumpster != "Grand Total", ) %>%
    mutate(year = as.integer(year))
```

#### Combining two dataframe

First add new column “trash_wheel” to both dataframe, assign “mr” to
Mr.Trash Wheel, and “professor” to Professor.Trash Wheel. Then use
`bind_rows()` to combine two data.

``` r
p2_df1$trash_wheel <- c("mr")
p2_df2$trash_wheel <- c("professor")
p2_df3 <- bind_rows(p2_df1, p2_df2) %>%
  janitor::clean_names()
p2_df3
```

    ## # A tibble: 641 × 15
    ##    dumpster month  year date                weight_tons volume…¹ plast…² polys…³
    ##       <dbl> <chr> <int> <dttm>                    <dbl>    <dbl>   <dbl>   <dbl>
    ##  1        1 May    2014 2014-05-16 00:00:00        4.31       18    1450    1820
    ##  2        2 May    2014 2014-05-16 00:00:00        2.74       13    1120    1030
    ##  3        3 May    2014 2014-05-16 00:00:00        3.45       15    2450    3100
    ##  4        4 May    2014 2014-05-17 00:00:00        3.1        15    2380    2730
    ##  5        5 May    2014 2014-05-17 00:00:00        4.06       18     980     870
    ##  6        6 May    2014 2014-05-20 00:00:00        2.71       13    1430    2140
    ##  7        7 May    2014 2014-05-21 00:00:00        1.91        8     910    1090
    ##  8        8 May    2014 2014-05-28 00:00:00        3.7        16    3580    4310
    ##  9        9 June   2014 2014-06-05 00:00:00        2.52       14    2400    2790
    ## 10       10 June   2014 2014-06-11 00:00:00        3.76       18    1340    1730
    ## # … with 631 more rows, 7 more variables: cigarette_butts <dbl>,
    ## #   glass_bottles <dbl>, grocery_bags <dbl>, chip_bags <dbl>,
    ## #   sports_balls <int>, homes_powered <dbl>, trash_wheel <chr>, and abbreviated
    ## #   variable names ¹​volume_cubic_yards, ²​plastic_bottles, ³​polystyrene

#### Summary of these data

Mr.Trash Wheel “p2_df1” includes amount of trash and debris collected in
Inner Harbor in Baltimore from 2014 to 2022. The data has 547 rows and
14 variables. The key variables are date, weight in tons, volume in
yards, types of trash, and estimate of homes powered by electricity from
incinerated trash. Mr Trash Wheel collect total of 856 sports balls in
2020.  
Professor.Trash Wheel “p2_df2” includes amount of trash and debris
collected in Canton neighborhood in Baltimore from 2017 to 2022. The
data has 94 rows and 13 variables. The key variables are same as
previous data. Professor TraSH Wheel collect a total weight of trash
190.12 tons.  
The merged data “p2_df3” contains all observations from Mr.Trash Wheel
and Professor.Trash Wheel which has 641 rows and 15 variables. The key
variables are the same as before along with extra columns that indicates
whether the data is from Mr.Trash Wheel or Professor.Trash Wheel.

# Problem 3

Read and clean data “pols-month”, “snp”, and “unemployment”. Breaking
the mon/date into year, month, and day. Replace the month
number/shortcut month to month name and remove day variable. Creat a new
variable president that taking the values of dem and gop for the first
data. Lastly taking the order by year and month.

``` r
p3_df1 <- read_csv("fivethirtyeight_datasets/pols-month.csv") %>%
  janitor::clean_names() %>%
  separate(mon, into = c("year", "month", "day")) %>%
  mutate(year = as.integer(year), month = as.integer(month), president = ifelse(prez_gop == 0, "dem", "gop")) %>%
  arrange(year, month) %>%
  mutate(month = month.name[month]) %>%
  select(-prez_dem, -prez_gop, -day)
head(p3_df1)
```

    ## # A tibble: 6 × 9
    ##    year month    gov_gop sen_gop rep_gop gov_dem sen_dem rep_dem president
    ##   <int> <chr>      <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl> <chr>    
    ## 1  1947 January       23      51     253      23      45     198 dem      
    ## 2  1947 February      23      51     253      23      45     198 dem      
    ## 3  1947 March         23      51     253      23      45     198 dem      
    ## 4  1947 April         23      51     253      23      45     198 dem      
    ## 5  1947 May           23      51     253      23      45     198 dem      
    ## 6  1947 June          23      51     253      23      45     198 dem

``` r
p3_df2 <- read_csv("fivethirtyeight_datasets/snp.csv") %>%
  janitor::clean_names() %>%
  separate(date, into = c("month", "day", "year")) %>%
  mutate(year = as.integer(year), year = ifelse(year >= 50, year + 1900, year + 2000), 
         month = as.integer(month)) %>%
  arrange(year, month) %>%
  mutate(month = month.name[month]) %>%
  select(year, month, close) 
head(p3_df2)
```

    ## # A tibble: 6 × 3
    ##    year month    close
    ##   <dbl> <chr>    <dbl>
    ## 1  1950 January   17.0
    ## 2  1950 February  17.2
    ## 3  1950 March     17.3
    ## 4  1950 April     18.0
    ## 5  1950 May       18.8
    ## 6  1950 June      17.7

``` r
p3_df3 <- read_csv("fivethirtyeight_datasets/unemployment.csv") %>%
  janitor::clean_names() %>%
  pivot_longer(jan:dec, names_to = "month", values_to = "unemployment") %>%
  mutate(month = recode(month, "jan" = "January", "feb" = "February", 
                        "mar" = "March", "apr" = "April", "may" = "May", 
                        "jun" = "June", "jul" = "July", "aug" = "August", 
                        "sep" = "September", "oct" = "October", "nov" = "November", 
                        "dec" = "December"))
head(p3_df3)
```

    ## # A tibble: 6 × 3
    ##    year month    unemployment
    ##   <dbl> <chr>           <dbl>
    ## 1  1948 January           3.4
    ## 2  1948 February          3.8
    ## 3  1948 March             4  
    ## 4  1948 April             3.9
    ## 5  1948 May               3.5
    ## 6  1948 June              3.6

#### Join the datasets.

By merging “snp” into “pols”, and merge “unemployment” into the result.

``` r
p3_df4 <- left_join(p3_df1, p3_df2, by = c("year", "month"))
head(p3_df4)
```

    ## # A tibble: 6 × 10
    ##    year month    gov_gop sen_gop rep_gop gov_dem sen_dem rep_dem president close
    ##   <dbl> <chr>      <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl> <chr>     <dbl>
    ## 1  1947 January       23      51     253      23      45     198 dem          NA
    ## 2  1947 February      23      51     253      23      45     198 dem          NA
    ## 3  1947 March         23      51     253      23      45     198 dem          NA
    ## 4  1947 April         23      51     253      23      45     198 dem          NA
    ## 5  1947 May           23      51     253      23      45     198 dem          NA
    ## 6  1947 June          23      51     253      23      45     198 dem          NA

``` r
final_data <- left_join(p3_df4, p3_df3, by = c("year", "month"))
head(final_data)
```

    ## # A tibble: 6 × 11
    ##    year month    gov_gop sen_gop rep_gop gov_dem sen_dem rep_dem president close
    ##   <dbl> <chr>      <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl> <chr>     <dbl>
    ## 1  1947 January       23      51     253      23      45     198 dem          NA
    ## 2  1947 February      23      51     253      23      45     198 dem          NA
    ## 3  1947 March         23      51     253      23      45     198 dem          NA
    ## 4  1947 April         23      51     253      23      45     198 dem          NA
    ## 5  1947 May           23      51     253      23      45     198 dem          NA
    ## 6  1947 June          23      51     253      23      45     198 dem          NA
    ## # … with 1 more variable: unemployment <dbl>

#### Check the number of missing values

``` r
sapply(final_data, function(close) sum(is.na(close)))
```

    ##         year        month      gov_gop      sen_gop      rep_gop      gov_dem 
    ##            0            0            0            0            0            0 
    ##      sen_dem      rep_dem    president        close unemployment 
    ##            0            0            0           36           12

#### Summary of these datasets

The pols_month “p3_df1” data frame includes the election results of two
party (Grand Old Party and Democratic Party) from 1947 to 2015. There
are 822 observations and 9 variables. The variables are year, month,
president party, and polls result of political party, House of
Representative, and senators.  
The snp “p3_df2” data frame contains the respective closing value of
stock index from 1950 to 2015. There are 787 observations and 3
variables. The variables are year, month, and closing value of stock
index.  
The unemployment “p3_df3” data frame contains the unemployment rate from
1948 to 2015. It has 816 observations and 3 variables which are year,
month, and unemployment rate.  
The final_data dataset merge the three data frames into a single one. It
has 822 observations and 11 variables. The variables are year, month,
president party, polls result of political party, polls result House of
Representative, polls result of senators, closing value of stock index,
and unemployment rate. The range is from 1947 to 2015 with a total of 68
years. There are 36 missing value of closing value and 12 missing value
of president since the range of year are different in three data frames.
