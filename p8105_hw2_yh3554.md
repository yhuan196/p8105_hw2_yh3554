p8105_hw1_yh3554
================

``` r
library(tidyverse)
library(readxl)
```

# Problem 1

Read and clean the data, select the variable we need, and convert entry
variable from character to logical variable.

``` r
p1_df = read_csv(
  "NYC_Transit_Subway_Entrance_And_Exit_Data.csv", 
  col_types = cols(Route8 = "c", Route9 = "c", Route10 = "c", Route11 = "c")) %>%
  janitor::clean_names() %>%
  select(
    line, station_name, station_latitude, station_longitude, 
    starts_with("route"), entry, vending, entrance_type, ada) %>%
  mutate(entry = ifelse(entry == "YES", TRUE, FALSE))
```

#### Description

The data contains 19 variables includes line, station, name, station
latitude, station longitude, 11 routes served, entry, vending, entrance
type, and ADA compliance. The dimension is 19 variables and 1868
observations. First, read the csv file and select the variable we need.
Then change the Route8, Route9, Route10, and Route11 variables to
character variable as same as Route1 to Route7 variables.  
The data is not “tidy” since there are 11 route variables which is not
necessary when we consider which route are selected. It would be easier
if we combine the route variables to a new variable that contains all
the route numbers. However, it would be different if we are focusing on
different aspect such as while we do need to consider the station level
variables.

#### Distinct stations

To find the numbers of distinct stations we need a news dataframe that
has both name and line variables, and use `distinct()` funtion to obtain
all unique combinations. There are 465 distinct stations in this data.

``` r
p1_df %>% 
  select(station_name, line) %>%
  distinct
```

    ## # A tibble: 465 × 2
    ##    station_name             line    
    ##    <chr>                    <chr>   
    ##  1 25th St                  4 Avenue
    ##  2 36th St                  4 Avenue
    ##  3 45th St                  4 Avenue
    ##  4 53rd St                  4 Avenue
    ##  5 59th St                  4 Avenue
    ##  6 77th St                  4 Avenue
    ##  7 86th St                  4 Avenue
    ##  8 95th St                  4 Avenue
    ##  9 9th St                   4 Avenue
    ## 10 Atlantic Av-Barclays Ctr 4 Avenue
    ## # … with 455 more rows

#### ADA Compliant Stations

To find the numbers of ADA compliant stations, we need to use the ada
variable to filter out the station that satisfy the ada compliant. Then
apply `distinct()` function again. There are 84 ADA compliant stations.

``` r
p1_df %>% 
  filter(ada == TRUE) %>%
  select(station_name, line) %>%
  distinct
```

    ## # A tibble: 84 × 2
    ##    station_name                   line           
    ##    <chr>                          <chr>          
    ##  1 Atlantic Av-Barclays Ctr       4 Avenue       
    ##  2 DeKalb Av                      4 Avenue       
    ##  3 Pacific St                     4 Avenue       
    ##  4 Grand Central                  42nd St Shuttle
    ##  5 34th St                        6 Avenue       
    ##  6 47-50th Sts Rockefeller Center 6 Avenue       
    ##  7 Church Av                      6 Avenue       
    ##  8 21st St                        63rd Street    
    ##  9 Lexington Av                   63rd Street    
    ## 10 Roosevelt Island               63rd Street    
    ## # … with 74 more rows

#### Proportion of station entrances/exits without vending allow entrance.

To find the proportion of station entrances/exists without vending allow
entrance, we first want to filter out the entry variable without vending
using `filter()` and `pull()`. After pull out the entry variable it
turns to logical variable. Then we can use `mean()` to compute the
proportion. The proportion is 0.3770.

``` r
p1_df %>%
  filter(vending == "NO") %>%
  pull(entry) %>%
  mean
```

    ## [1] 0.3770492

#### Numbers of dictinct stations serve A

Create two new variables route number and route name using
`pivot_longer()`, then filter out distinct stations that serve A. There
are 60 distinct stations that serve A.

``` r
p1_df %>% pivot_longer(route1:route11,
                       names_to = "station_number",
                       values_to = "route_name") %>%
  filter(route_name == "A") %>%
  select(station_name, line) %>%
  distinct
```

    ## # A tibble: 60 × 2
    ##    station_name                  line           
    ##    <chr>                         <chr>          
    ##  1 Times Square                  42nd St Shuttle
    ##  2 125th St                      8 Avenue       
    ##  3 145th St                      8 Avenue       
    ##  4 14th St                       8 Avenue       
    ##  5 168th St - Washington Heights 8 Avenue       
    ##  6 175th St                      8 Avenue       
    ##  7 181st St                      8 Avenue       
    ##  8 190th St                      8 Avenue       
    ##  9 34th St                       8 Avenue       
    ## 10 42nd St                       8 Avenue       
    ## # … with 50 more rows

#### Numbers of distinct stations are ADA compliant that serve A.

Similar as before, just add ADA compliant to the filter. There are 17
distinct stations are ADA compliant that serve A.

``` r
p1_df %>% pivot_longer(route1:route11,
                       names_to = "station_number",
                       values_to = "route_name") %>%
  filter(route_name == "A", ada == TRUE) %>%
  select(station_name, line) %>%
  distinct
```

    ## # A tibble: 17 × 2
    ##    station_name                  line            
    ##    <chr>                         <chr>           
    ##  1 14th St                       8 Avenue        
    ##  2 168th St - Washington Heights 8 Avenue        
    ##  3 175th St                      8 Avenue        
    ##  4 34th St                       8 Avenue        
    ##  5 42nd St                       8 Avenue        
    ##  6 59th St                       8 Avenue        
    ##  7 Inwood - 207th St             8 Avenue        
    ##  8 West 4th St                   8 Avenue        
    ##  9 World Trade Center            8 Avenue        
    ## 10 Times Square-42nd St          Broadway        
    ## 11 59th St-Columbus Circle       Broadway-7th Ave
    ## 12 Times Square                  Broadway-7th Ave
    ## 13 8th Av                        Canarsie        
    ## 14 Franklin Av                   Franklin        
    ## 15 Euclid Av                     Fulton          
    ## 16 Franklin Av                   Fulton          
    ## 17 Howard Beach                  Rockaway

# Problem 2

Read and clean the data “Mr.Trash Wheel”. Assign appropriate column name
to each variables and exclude rows or columns that containing notes or
non-data entries.

``` r
p2_df1 <- read_excel("Trash-Wheel-Collection-Totals-7-2020-2.xlsx", sheet = 1) %>%
    janitor::clean_names() %>%
    filter(dumpster != "NA", dumpster != "Grand Total", ) %>%
    select(-c(15, 16, 17)) %>%
    mutate(sports_balls = as.integer(sports_balls))
```

    ## New names:
    ## • `` -> `...15`
    ## • `` -> `...16`
    ## • `` -> `...17`

``` r
p2_df2 <- read_excel("Trash-Wheel-Collection-Totals-7-2020-2.xlsx", sheet = 2) %>%
    janitor::clean_names() %>%
    filter(dumpster != "NA", dumpster != "Grand Total", ) %>%
    mutate(dumpster = as.character(dumpster), sports_balls = as.integer(sports_balls))
```

#### Combining two dataframe

First add new column “trash_wheel” to both dataframe, assign “mr” to
Mr.Trash Wheel, and “professor” to Professor.Trash Wheel. Then use
`bind_rows()` to combine two data.

``` r
p2_df1$trash_wheel <- c("mr")
p2_df2$trash_wheel <- c("professor")
p2_df3 <- bind_rows(p2_df1, p2_df2) %>%
  janitor::clean_names()
p2_df3
```

    ## # A tibble: 524 × 15
    ##    dumpster month  year date                weight_tons volume…¹ plast…² polys…³
    ##    <chr>    <chr> <dbl> <dttm>                    <dbl>    <dbl>   <dbl>   <dbl>
    ##  1 1        May    2014 2014-05-16 00:00:00        4.31       18    1450    1820
    ##  2 2        May    2014 2014-05-16 00:00:00        2.74       13    1120    1030
    ##  3 3        May    2014 2014-05-16 00:00:00        3.45       15    2450    3100
    ##  4 4        May    2014 2014-05-17 00:00:00        3.1        15    2380    2730
    ##  5 5        May    2014 2014-05-17 00:00:00        4.06       18     980     870
    ##  6 6        May    2014 2014-05-20 00:00:00        2.71       13    1430    2140
    ##  7 7        May    2014 2014-05-21 00:00:00        1.91        8     910    1090
    ##  8 8        May    2014 2014-05-28 00:00:00        3.7        16    3580    4310
    ##  9 9        June   2014 2014-06-05 00:00:00        2.52       14    2400    2790
    ## 10 10       June   2014 2014-06-11 00:00:00        3.76       18    1340    1730
    ## # … with 514 more rows, 7 more variables: cigarette_butts <dbl>,
    ## #   glass_bottles <dbl>, grocery_bags <dbl>, chip_bags <dbl>,
    ## #   sports_balls <int>, homes_powered <dbl>, trash_wheel <chr>, and abbreviated
    ## #   variable names ¹​volume_cubic_yards, ²​plastic_bottles, ³​polystyrene

#### Summary of these data

Mr.Trash Wheel includes amount of trash and debris collected in Inner
Harbor in Baltimore from May 2014 to Jan 2021. The data has 453 rows and
14 variables. The key variables are date, weight in tons, volume in
yards, types of trash, and estimate of homes powered by electricity from
incinerated trash. Mr Trash Wheel collect total of 856 sports balls in
2020.  
Professor.Trash Wheel includes amount of trash and debris collected in
Canton neighborhood in Baltimore from Jan 2017 to Jan 2021. The data has
71 rows and 14 variables. The key variables are same as previous data.
Professor TraSH Wheel collect a total weight of trash 135.5 tons.  
The final data “p2_df3” contains all observations from Mr.Trash Wheel
and Professor.Trash Wheel which has 524 rows and 15 variables. The key
variables are the same as before along with extra columns that indicates
whether the data is from Mr.Trash Wheel or Professor.Trash Wheel.
